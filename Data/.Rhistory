knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.align = "center", fig.height = 6, fig.width = 8)
# Chunk 2
library(fpp)
lsunspot100 <- window(log(sunspotarea), start = 1875, end = 1974)
fit_ar10 <- arima(lsunspot100, order = c(10, 0, 0))
# Chunk 3
# prediction an AR(10) model with 100 observations
pred <- predict(fit_ar10, n.ahead = 100)
plot(lsunspot100, xlim = c(1875, 2074))
# the estimated global mean
abline(h = fit_ar10$coef["intercept"], lty = 3)
# prediction line
lines(pred$pred, col = "violet")
# Chunk 4
# prediction an AR(10) model with 37 observations
pred37 <- predict(fit_ar10, n.ahead = 37)
plot(log(sunspotarea), ylim = c(2, 10))
# prediction line
lines(pred37$pred, col = "red", lwd = 3)
# interval
lines(pred37$pred + 1.96 * pred37$se, col = "red", lty = 2)
lines(pred37$pred - 1.96 * pred37$se, col = "blue", lty = 2)
# mean squared error MSME
pred_error <- window(log(sunspotarea), start = 1975, end = 2011) - pred37$pred
(pred_mse <- mean(pred_error^2))
library(forecast)
# load data
d_air <- AirPassengers
# only data to 1957
d_air_1956 <- window(d_air, end = c(1956, 12))
# log transformation
d_air_1956_log <- log(d_air_1956)
# first differencing
d_air_1956_diff1 <- diff(d_air_1956_log, lag = 12)
# second differencing
d_air_1956_diff2 <- diff(d_air_1956_diff1, 1)
# ACF & PACF
tsdisplay(d_air_1956_diff2, points = FALSE)
s1_air <- arima(d_air_1956_log, order = c(0, 1, 1),seasonal = c(0, 1, 1))
s1_air
# Fit SARIMA model
s1_air <- arima(d_air_1956_log, order = c(0, 1, 1),seasonal = c(0, 1, 1))
s1_air
# PACF & PACF SARIMA
tsdisplay(s1_air$residuals, points = FALSE)
# PACF & PACF SARIMA
tsdisplay(s1_air$residuals)
predict_sarima <- predict(s1_air, n.ahead = 48)
plot(log(d_air), xlim = c(1950, 1961), ylim = c(4.5, 7.5))
interval1 <- predict_sarima$pred + 1.96 * predict_sarima$se
interval2 <- predict_sarima$pred - 1.96 * predict_sarima$se
lines(predict_sarima$pred, col = "red")
lines(interval1, col = "blue", lty = 2)
lines(interval2, col = "pink", lty = 2)
lines(interval2, col = "yellow", lty = 2)
lines(interval2, col = "violet", lty = 2)
# Prediction SARIMA
predict_sarima <- predict(s1_air, n.ahead = 48)
plot(log(d_air), xlim = c(1950, 1961), ylim = c(4.5, 7.5))
lines(predict_sarima$pred, col = "red")
# Adding the interval
interval1 <- predict_sarima$pred + 1.96 * predict_sarima$se
interval2 <- predict_sarima$pred - 1.96 * predict_sarima$se
lines(interval1, col = "blue", lty = 2)
lines(interval2, col = "violet", lty = 2)
fit <- stl(d_air_1956_log, s.window = "periodic")
trend <- fit$time.series[, 2]
## Least Squares for trend over the last 4 years
yy <- window(trend, start = c(1953, 1))
xx <- time(yy)
reg <- lm(yy ~ xx)
## Trend Extrapolation
kk <- 48
trend.ex <- rev(trend)[1] + ((1:kk) / 12) * coef(reg)[2]
## seasonality
season <- fit$time.series[, 1]
season_window <- window(season, start = c(1953, 1))
season_1957_1960 <- ts(season_window, start = c(1957, 1), end = c(1960, 12), frequency = 12)
season_1957_1960 <- ts(season_window, start = c(1957, 1),
end = c(1960, 12), frequency = 12)
## remainder
remainder <- fit$time.series[, 3]
tsdisplay(remainder, points = FALSE)
fit_ar3 <- arima(remainder, order = c(3, 0, 0))
tsdisplay(resid(fit_ar3))
pred <- predict(fit_ar3, n.ahead = 48)
pred_pred <- pred$pred
trend_ex <- rev(trend)[1] + ((1:kk) / 12) * coef(reg)[2]
remainder_pred <- pred$pred
## everything together
ts_ex <- trend_ex + season_1957_1960 + remainder_pred
## Plotting
plot(log(d_air), xlim = c(1950, 1961), ylim = c(4.5, 7.5))
lines(ts_ex, col = "red", lwd = 2)
ts_air_forecast <- window(log(d.air), start = c(1957,1), end = c(1960, 12))
# SARIMA
mean((ts_air_forecast - predict_sarima$pred)^2)
ts_air_forecast <- window(log(d.air), start = c(1957,1), end = c(1960, 12))
# SARIMA
mean((ts_air_forecast - predict_sarima$pred)^2)
ts_air_forecast <- window(log(d.air), start = c(1957,1), end = c(1960, 12))
ts_air_forecast <- window(log(d_air), start = c(1957,1), end = c(1960, 12))
# SARIMA
mean((ts_air_forecast - predict_sarima$pred)^2)
# STL
mean((ts_air_forecast - ts_ex)^2)
library(AER)
data("Guns")
summary(Guns)
str(Guns)
years
# verify that panel is balanced
years <- length(levels(Guns$year))
years
states <- length(levels(Guns$state))
years * states == nrow(Guns)
library(plm)
install.packages("plm")
library(plm)
install.packages("installr")
library(installr)
updateR()
updateR()
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
library(plm)
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
library(plm)
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(AER)
data("Guns")
# Chunk 3
summary(Guns)
str(Guns)
# Chunk 4
# verify that panel is balanced
years <- length(levels(Guns$year))
states <- length(levels(Guns$state))
years * states == nrow(Guns)
str(Guns)
model.se
law
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
model.se
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(AER)
data("Guns")
# Chunk 3
summary(Guns)
str(Guns)
# Chunk 4
# verify that panel is balanced
years <- length(levels(Guns$year))
states <- length(levels(Guns$state))
years * states == nrow(Guns)
library(plm)
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
model.se
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
# Chunk 2
library(AER)
data("Guns")
# Chunk 3
summary(Guns)
str(Guns)
# Chunk 4
# verify that panel is balanced
years <- length(levels(Guns$year))
states <- length(levels(Guns$state))
years * states == nrow(Guns)
library(plm)
model.se <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "within")
View(model.se)
View(model.se)
model.se
# summary using robust standard errors
coeftest(model.se, vcov. = vcovHC, type = "HC1")
# summary using robust standard errors
coeftest(model.se, vcov. = vcovHC, type = "HC1")
model <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "pooling")
pFtest(model.se, model)
coeftest(model, vcov. = vcovHC, type = "HC1")
library(RMySQL)
library(dplyr)
library(ggplot2)
library(forcats)
library(gridExtra)
library(GGally)
library(hrbrthemes)
library(viridis)
library(RMySQL)
library(DBI)
library(plotly)
library(ggplot2)
library(tidyverse)
db = dbConnect(MySQL(), user="n", password="mojitodb",
dbname="migration",
host="db-vm-21.el.eee.intern", port=3306)
my_theme_general <- theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
text = element_text(size = 11))
# Query 1
## Top 10 base countries by sum migration over the years
top_inflow_countries_total <- dbGetQuery(db, "Select Base_Country_Code, Country_Name, round(sum(Value),1) as sum_migration
from countrymigration, country
where Base_Country_Code = Country_Code
group by Base_Country_Code
order by sum_migration desc
limit 10")
db = dbConnect(MySQL(), user="q", password="mojitodb",
dbname="migration",
host="db-vm-21.el.eee.intern", port=3306)
db = dbConnect(MySQL(), user="q", password="mojitodb",
dbname="migration",
host="db-vm-21.el.eee.intern", port=3306)
my_theme_general <- theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
text = element_text(size = 11))
# Query 1
## Top 10 base countries by sum migration over the years
top_inflow_countries_total <- dbGetQuery(db, "Select Base_Country_Code, Country_Name, round(sum(Value),1) as sum_migration
from countrymigration, country
where Base_Country_Code = Country_Code
group by Base_Country_Code
order by sum_migration desc
limit 10")
library(RMySQL)
install.packages("RSQL")
library(RMySQL)
library(RMySQL)
install.packages("RMySQL")
library(RMySQL)
db = dbConnect(MySQL(), user="q", password="mojitodb",
dbname="migration",
host="db-vm-21.el.eee.intern", port=3306)
my_theme_general <- theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
text = element_text(size = 11))
# Query 1
## Top 10 base countries by sum migration over the years
top_inflow_countries_total <- dbGetQuery(db, "Select Base_Country_Code, Country_Name, round(sum(Value),1) as sum_migration
from countrymigration, country
where Base_Country_Code = Country_Code
group by Base_Country_Code
order by sum_migration desc
limit 10")
plot1 <- top_inflow_countries_total %>%
mutate(Country_Name = fct_reorder(Country_Name, sum_migration)) %>%
ggplot( aes(x=Country_Name, y=sum_migration, label = sum_migration)) +
geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4) +
geom_text(vjust = -0.5, size = 3) +
coord_flip() +
xlab("Country of destination") +
ylab("Sum migration") +
my_theme_general
## Top 10 target countries by sum migration over the years
top_outflow_countries_total <- dbGetQuery(db, "Select Base_Country_Code, Country_Name, round(sum(Value),1) as sum_migration
from countrymigration, country
where Base_Country_Code = Country_Code
group by Base_Country_Code
order by sum_migration asc
limit 10")
plot2 <- top_outflow_countries_total %>%
mutate(Country_Name = fct_reorder(Country_Name, sum_migration)) %>%
ggplot( aes(x=Country_Name, y=sum_migration, label = sum_migration)) +
geom_bar(stat="identity", fill="#f68060", alpha=.6, width=.4)+
geom_text(vjust = -0.5, size = 3) +
coord_flip() +
xlab("Country of departure") +
ylab("Sum migration")+
my_theme_general
model <- plm(log(violent) ~ law, data = Guns, index = c("state", "year"),
model = "pooling")
coeftest(model, vcov. = vcovHC, type = "HC1")
pFtest(model.se, model)
coeftest(model, vcov. = vcovHC, type = "HC1")
# summary using robust standard errors
coeftest(model.se, vcov. = vcovHC, type = "HC1")
pFtest(model.se, model)
?pFtest
install.packages("naivebayes")
install.packages("class")
install.packages("pROC")
install.packages("rpart")
data(spam)
str(spam)
library(randomForest)
set.seed(123)
# Task 2
## Load data & library
data(spam)
# Task 2
## Load data & library
library(kernlab)
data(spam)
str(spam)
spam$spam
##
system.time(rf.spam <- randomForest(type ~., data = spam))
rf.spam
## b) Plot the error rate vs. the number of fitted trees.
## How many trees are necessary?
## Refit the model with the chosen number of trees. How long does it take now?
plot(rf.spam)
system.time(rf.spam <- randomForest(type ~., data = spam, ntree = 100))
set.seed(123)
system.time(rf.spam <- randomForest(type ~., data = spam, ntree = 100))
rf.spam
idx <- sample(1:nrow(spam), 2601)
dTrain <- spam[idx,]
dTest <-spam[-idx,]
rf.train <- randomForest(type ~., data = dTrain, ntree = 100)
rf.train
pred.rf <- predict(rf.train, newdata = dTest)
mean(pred.rf != dTest$spam)
pred.rf <- predict(rf.train, newdata = dTest)
mean(pred.rf != dTest$spam)
pred.rf <- predict(rf.train, newdata = dTest)
accuracy(pred.rf, dTest$type)
?accuracy
??accuracy
library(forecast)
accuracy(pred.rf, dTest$type)
pred.rf
conf_matrix <- confusionMatrix(pred.rf, dTest$type)
??confusionMatrix
library(caret)
conf_matrix <- confusionMatrix(pred.rf, dTest$type)
conf_matrix
mean(pred.rf != dTest$type)
rf.spam
## a) Fit the model with default
set.seed(123)
system.time(rf.spam <- randomForest(type ~., data = spam))
rf.spam
## b) Plot the error rate vs. the number of fitted trees.
## How many trees are necessary?
## Refit the model with the chosen number of trees. How long does it take now?
plot(rf.spam)
# We choose 100 trees as more trees result in no improvement.
set.seed(123)
system.time(rf.spam <- randomForest(type ~., data = spam, ntree = 100))
rf.spam
## a) Fit the model with default
set.seed(123)
system.time(rf.spam <- randomForest(type ~., data = spam))
rf.spam
# We choose 100 trees as more trees result in no improvement.
set.seed(123)
system.time(rf.spam <- randomForest(type ~., data = spam, ntree = 100))
rf.spam
# The OOB error rate from c) is 4.8% and the out-of-sample test error rate is 4.7%
mean(pred.rf != dTest$type)
## d) Suppose we get a new email and want to predict the spam label.
## For simplicity, we refit the Random Forest on 2601 randomly chosen emails and save the remaining 2000 emails as test set.
## How does the OOB error compare with the error on the test set? (use ntree = 100, and set.seed = 123)
### Create train & test set
idx <- sample(1:nrow(spam), 2601)
dTrain <- spam[idx,]
dTest <-spam[-idx,]
### Fit model
set.seed(123)
rf.train <- randomForest(type ~., data = dTrain, ntree = 100)
rf.train
### predict
pred.rf <- predict(rf.train, newdata = dTest)
conf_matrix <- confusionMatrix(pred.rf, dTest$type)
# The OOB error rate from c) is 4.8% and the out-of-sample test error rate is 4.7%
mean(pred.rf != dTest$type)
idx <- sample(1:nrow(spam), 2601)
dTrain <- spam[idx,]
dTest <-spam[-idx,]
### Fit model
set.seed(123)
rf.train <- randomForest(type ~., data = dTrain, ntree = 100)
rf.train
### predict
pred.rf <- predict(rf.train, newdata = dTest)
conf_matrix <- confusionMatrix(pred.rf, dTest$type)
# The OOB error rate from c) is 4.8% and the out-of-sample test error rate is 4.7%
mean(pred.rf != dTest$type)
### Fit model
set.seed(123)
rf.train <- randomForest(type ~., data = dTrain, ntree = 100)
rf.train
### predict
pred.rf <- predict(rf.train, newdata = dTest)
# The OOB error rate from c) is 4.8% and the out-of-sample test error rate is 4.7%
mean(pred.rf != dTest$type)
system.time(rf.spam1 <- randomForest(type ~., data = spam))
rf.spam1
## a) Fit the model with default
set.seed(123)
system.time(rf.spam1 <- randomForest(type ~., data = spam))
rf.spam1
## b) Plot the error rate vs. the number of fitted trees.
## How many trees are necessary?
## Refit the model with the chosen number of trees. How long does it take now?
plot(rf.spam)
## b) Plot the error rate vs. the number of fitted trees.
## How many trees are necessary?
## Refit the model with the chosen number of trees. How long does it take now?
plot(rf.spam1)
system.time(rf.spam2 <- randomForest(type ~., data = spam, ntree = 100))
rf.spam2
# We choose 100 trees as more trees result in no improvement.
set.seed(123)
system.time(rf.spam2 <- randomForest(type ~., data = spam, ntree = 100))
rf.spam2
## d) Suppose we get a new email and want to predict the spam label.
## For simplicity, we refit the Random Forest on 2601 randomly chosen emails and save the remaining 2000 emails as test set.
## How does the OOB error compare with the error on the test set? (use ntree = 100, and set.seed = 123)
### Create train & test set
idx <- sample(1:nrow(spam), 2601)
dTrain <- spam[idx,]
dTest <-spam[-idx,]
### Fit model
set.seed(123)
rf.train <- randomForest(type ~., data = dTrain, ntree = 100)
rf.train
### predict
pred.rf <- predict(rf.train, newdata = dTest)
conf_matrix <- confusionMatrix(pred.rf, dTest$type)
# The OOB error rate from c) is 4.8% and the out-of-sample test error rate is 4.7%
mean(pred.rf != dTest$type)
# e) Suppose we don't want to compute all variables for each new incoming mail, but only use the 5 most important ones.
# Which 5 variables should we choose?
# Compare the OOB error using all variables, the 5 most important and the 5 least important ones (according to decrease in accuracy; use ntree = 100 and seed = 123).
set.seed(123)
rf.spam3 <- randomForest(type ~ ., data = spam, importance = TRUE, ntree = 100)
varImpPlot(rf.spam3, n.var = ncol(spam)-1)
rf.spam3
rf.best <- randomForest(type ~ A.52 + A.55 + A.7 + A.56 + A.53, data = spam, ntree = 100)
rf.best <- randomForest(type ~ CharExclamation + remove + charDollar + free + capitalAve, data = spam, ntree = 100)
rf.best <- randomForest(type ~ CharExclamation + remove + charDollar + free + capitalAve, data = spam, ntree = 100)
rf.best <- randomForest(type ~ charExclamation + remove + charDollar + free + capitalAve, data = spam, ntree = 100)
rf.best
# Worst 5 vars
rf.worst <- randomForest(type ~ table + parts + num857 + num415 + num3d, data = spam, ntree = 100)
rf.worst
library(pagedown)
install.packages("pagedown")
##
df3 %>%
select(`Regional indicator`)
##
df3 %>%
select(Regional indicator)
##
df3 %>%
select(`Regional indicator`)
library(tidyverse)
library(readxl)
library("writexl")
##
df3 %>%
select(`Regional indicator`)
# Prepocessing data before tableau
## Load two datasets
df1 <- read_excel("Appendix_2_Data_for_Figure_2.1_latest.xls")
glimpse(df1)
## Clean the * after country names to join later with the previous year
df1 <- df1 %>%
mutate(Country = str_remove_all(Country, "\\*"))
df2 <- read_excel("DataForFigure2.1WHR2021C2.xls")
df2
## Keeping region column from previous year data
df3 <- df1 %>%
left_join(df2 %>% select(`Country name`, `Regional indicator`),
by = c("Country" = "Country name")
)
## Check the new created dataframe
df3 %>% View()
## Remove NA row with country called xx
df3 <- df3 %>%
filter(!Country == "xx")
## Check again
glimpse(df3)
##
df3 %>%
select(`Regional indicator`)
setwd("C:/Users/duong/Google Drive/HSLU 3rd semester/Data Visualisation and Narration/Project/Data")
Country
# Prepocessing data before tableau
## Load two datasets
df1 <- read_excel("Appendix_2_Data_for_Figure_2.1_latest.xls")
glimpse(df1)
## Clean the * after country names to join later with the previous year
df1 <- df1 %>%
mutate(Country = str_remove_all(Country, "\\*"))
df2 <- read_excel("DataForFigure2.1WHR2021C2.xls")
df2
## Keeping region column from previous year data
df3 <- df1 %>%
left_join(df2 %>% select(`Country name`, `Regional indicator`),
by = c("Country" = "Country name"))
## Check the new created dataframe
df3 %>% View()
